{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "data = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/mlflow/mlflow/master/tests/datasets/winequality-white.csv\",\n",
    "    sep=\";\",\n",
    ")\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "train, test = train_test_split(data, test_size=0.25, random_state=42)\n",
    "train_x = train.drop([\"quality\"], axis=1).values\n",
    "train_y = train[[\"quality\"]].values.ravel()\n",
    "test_x = test.drop([\"quality\"], axis=1).values\n",
    "test_y = test[[\"quality\"]].values.ravel()\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(\n",
    "    train_x, train_y, test_size=0.2, random_state=42\n",
    ")\n",
    "signature = infer_signature(train_x, train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(params, epochs, train_x, train_y, valid_x, valid_y, test_x, test_y):\n",
    "    # Define model architecture\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            keras.Input([train_x.shape[1]]),\n",
    "            keras.layers.Normalization(mean=np.mean(train_x), variance=np.var(train_x)),\n",
    "            keras.layers.Dense(64, activation=\"relu\"),\n",
    "            keras.layers.Dense(1),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.SGD(\n",
    "            learning_rate=params[\"lr\"], momentum=params[\"momentum\"]\n",
    "        ),\n",
    "        loss=\"mean_squared_error\",\n",
    "        metrics=[keras.metrics.RootMeanSquaredError()],\n",
    "    )\n",
    "\n",
    "    with mlflow.start_run(nested=True):\n",
    "        model.fit(\n",
    "            train_x,\n",
    "            train_y,\n",
    "            epochs=epochs,\n",
    "            validation_data=(valid_x, valid_y),\n",
    "            batch_size=64,\n",
    "            callbacks=[\n",
    "                keras.callbacks.EarlyStopping(\n",
    "                    patience=3, restore_best_weights=True\n",
    "                )\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        # Evaluate model on the test data subset\n",
    "        eval_result = model.evaluate(test_x, test_y)\n",
    "        eval_rmse = eval_result[1]\n",
    "\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_metrics({\"rmse\": eval_rmse})\n",
    "\n",
    "        # Log the model within the MLflow run\n",
    "        mlflow.tensorflow.log_model(model, \"model\", signature=signature)\n",
    "\n",
    "        return {\"eval_rmse\": eval_rmse, \"status\": STATUS_OK, \"model\": model, \"loss\": eval_rmse}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    # MLflow will track the parameters and results for each run\n",
    "    result = train_model(\n",
    "        params,\n",
    "        epochs=3,\n",
    "        train_x=train_x,\n",
    "        train_y=train_y,\n",
    "        valid_x=valid_x,\n",
    "        valid_y=valid_y,\n",
    "        test_x=test_x,\n",
    "        test_y=test_y,\n",
    "    )\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "    \"lr\": hp.loguniform(\"lr\", np.log(1e-5), np.log(1e-1)),\n",
    "    \"momentum\": hp.uniform(\"momentum\", 0.0, 1.0),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3                                            \n",
      "\n",
      "  0%|          | 0/8 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-11 11:15:33.370788: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node SGD/AssignVariableOp.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/46 [..............................] - ETA: 9s - loss: 34.5240 - root_mean_squared_error: 5.8757\n",
      " 9/46 [====>.........................] - ETA: 0s - loss: 19.6085 - root_mean_squared_error: 4.4282\n",
      "18/46 [==========>...................] - ETA: 0s - loss: 11.8584 - root_mean_squared_error: 3.4436\n",
      "27/46 [================>.............] - ETA: 0s - loss: 9.1147 - root_mean_squared_error: 3.0191 \n",
      "35/46 [=====================>........] - ETA: 0s - loss: 7.7614 - root_mean_squared_error: 2.7859\n",
      "43/46 [===========================>..] - ETA: 0s - loss: 6.8848 - root_mean_squared_error: 2.6239\n",
      "46/46 [==============================] - ETA: 0s - loss: 6.6736 - root_mean_squared_error: 2.5833\n",
      "46/46 [==============================] - 1s 22ms/step - loss: 6.6736 - root_mean_squared_error: 2.5833 - val_loss: 3.2331 - val_root_mean_squared_error: 1.7981\n",
      "\n",
      "Epoch 2/3                                            \n",
      "\n",
      " 1/46 [..............................] - ETA: 0s - loss: 3.8885 - root_mean_squared_error: 1.9719\n",
      "11/46 [======>.......................] - ETA: 0s - loss: 2.9831 - root_mean_squared_error: 1.7272\n",
      "21/46 [============>.................] - ETA: 0s - loss: 2.9740 - root_mean_squared_error: 1.7245\n",
      "31/46 [===================>..........] - ETA: 0s - loss: 2.9753 - root_mean_squared_error: 1.7249\n",
      "41/46 [=========================>....] - ETA: 0s - loss: 2.8979 - root_mean_squared_error: 1.7023\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 2.8383 - root_mean_squared_error: 1.6847 - val_loss: 2.7255 - val_root_mean_squared_error: 1.6509\n",
      "\n",
      "Epoch 3/3                                            \n",
      "\n",
      " 1/46 [..............................] - ETA: 0s - loss: 3.0376 - root_mean_squared_error: 1.7429\n",
      "11/46 [======>.......................] - ETA: 0s - loss: 2.5182 - root_mean_squared_error: 1.5869\n",
      "21/46 [============>.................] - ETA: 0s - loss: 2.4994 - root_mean_squared_error: 1.5810\n",
      "31/46 [===================>..........] - ETA: 0s - loss: 2.4690 - root_mean_squared_error: 1.5713\n",
      "41/46 [=========================>....] - ETA: 0s - loss: 2.4103 - root_mean_squared_error: 1.5525\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 2.3988 - root_mean_squared_error: 1.5488 - val_loss: 2.3065 - val_root_mean_squared_error: 1.5187\n",
      "\n",
      " 1/39 [..............................] - ETA: 1s - loss: 2.7106 - root_mean_squared_error: 1.6464\n",
      "13/39 [=========>....................] - ETA: 0s - loss: 2.4183 - root_mean_squared_error: 1.5551\n",
      "25/39 [==================>...........] - ETA: 0s - loss: 2.5405 - root_mean_squared_error: 1.5939\n",
      "37/39 [===========================>..] - ETA: 0s - loss: 2.4251 - root_mean_squared_error: 1.5573\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 2.4303 - root_mean_squared_error: 1.5589\n",
      "\n",
      "  0%|          | 0/8 [00:02<?, ?trial/s, best loss=?]INFO:tensorflow:Assets written to: /var/folders/ld/8bgljzsn4sx_x1lb3wl_mnnm0000gn/T/tmpjwnh1xst/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/ld/8bgljzsn4sx_x1lb3wl_mnnm0000gn/T/tmpjwnh1xst/model/data/model/assets\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 1/8 [00:05<00:41,  5.87s/trial, best loss: 1.5589367151260376]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3                                                                      \n",
      "\n",
      " 1/46 [..............................] - ETA: 9s - loss: 24.3062 - root_mean_squared_error: 4.9301\n",
      " 9/46 [====>.........................] - ETA: 0s - loss: 8.4043 - root_mean_squared_error: 2.8990 \n",
      "19/46 [===========>..................] - ETA: 0s - loss: 5.4419 - root_mean_squared_error: 2.3328\n",
      "28/46 [=================>............] - ETA: 0s - loss: 4.5676 - root_mean_squared_error: 2.1372\n",
      "38/46 [=======================>......] - ETA: 0s - loss: 3.8866 - root_mean_squared_error: 1.9714\n",
      "46/46 [==============================] - ETA: 0s - loss: 3.5541 - root_mean_squared_error: 1.8852\n",
      "46/46 [==============================] - 1s 10ms/step - loss: 3.5541 - root_mean_squared_error: 1.8852 - val_loss: 1.7856 - val_root_mean_squared_error: 1.3363\n",
      "\n",
      "Epoch 2/3                                                                      \n",
      "\n",
      " 1/46 [..............................] - ETA: 0s - loss: 1.7182 - root_mean_squared_error: 1.3108\n",
      "11/46 [======>.......................] - ETA: 0s - loss: 1.5544 - root_mean_squared_error: 1.2467\n",
      "21/46 [============>.................] - ETA: 0s - loss: 1.4998 - root_mean_squared_error: 1.2247\n",
      "31/46 [===================>..........] - ETA: 0s - loss: 1.4051 - root_mean_squared_error: 1.1854\n",
      "41/46 [=========================>....] - ETA: 0s - loss: 1.3473 - root_mean_squared_error: 1.1607\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 1.3103 - root_mean_squared_error: 1.1447 - val_loss: 1.0219 - val_root_mean_squared_error: 1.0109\n",
      "\n",
      "Epoch 3/3                                                                      \n",
      "\n",
      " 1/46 [..............................] - ETA: 0s - loss: 0.7793 - root_mean_squared_error: 0.8828\n",
      "11/46 [======>.......................] - ETA: 0s - loss: 0.9427 - root_mean_squared_error: 0.9709\n",
      "22/46 [=============>................] - ETA: 0s - loss: 0.9296 - root_mean_squared_error: 0.9642\n",
      "32/46 [===================>..........] - ETA: 0s - loss: 0.9207 - root_mean_squared_error: 0.9595\n",
      "42/46 [==========================>...] - ETA: 0s - loss: 0.9104 - root_mean_squared_error: 0.9542\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 0.9232 - root_mean_squared_error: 0.9608 - val_loss: 0.8358 - val_root_mean_squared_error: 0.9142\n",
      "\n",
      " 1/39 [..............................] - ETA: 1s - loss: 1.3672 - root_mean_squared_error: 1.1693\n",
      "14/39 [=========>....................] - ETA: 0s - loss: 0.8557 - root_mean_squared_error: 0.9250\n",
      "27/39 [===================>..........] - ETA: 0s - loss: 0.8549 - root_mean_squared_error: 0.9246\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.8315 - root_mean_squared_error: 0.9119\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.8315 - root_mean_squared_error: 0.9119\n",
      "\n",
      " 12%|█▎        | 1/8 [00:07<00:41,  5.87s/trial, best loss: 1.5589367151260376]INFO:tensorflow:Assets written to: /var/folders/ld/8bgljzsn4sx_x1lb3wl_mnnm0000gn/T/tmpyajmsft0/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/ld/8bgljzsn4sx_x1lb3wl_mnnm0000gn/T/tmpyajmsft0/model/data/model/assets\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 2/8 [00:10<00:31,  5.25s/trial, best loss: 0.9118534326553345]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3                                                                      \n",
      "\n",
      " 1/46 [..............................] - ETA: 9s - loss: 31.7387 - root_mean_squared_error: 5.6337\n",
      " 9/46 [====>.........................] - ETA: 0s - loss: nan - root_mean_squared_error: nan       \n",
      "18/46 [==========>...................] - ETA: 0s - loss: nan - root_mean_squared_error: nan\n",
      "28/46 [=================>............] - ETA: 0s - loss: nan - root_mean_squared_error: nan\n",
      "38/46 [=======================>......] - ETA: 0s - loss: nan - root_mean_squared_error: nan\n",
      "46/46 [==============================] - ETA: 0s - loss: nan - root_mean_squared_error: nan\n",
      "46/46 [==============================] - 1s 10ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "\n",
      "Epoch 2/3                                                                      \n",
      "\n",
      " 1/46 [..............................] - ETA: 0s - loss: nan - root_mean_squared_error: nan\n",
      "11/46 [======>.......................] - ETA: 0s - loss: nan - root_mean_squared_error: nan\n",
      "21/46 [============>.................] - ETA: 0s - loss: nan - root_mean_squared_error: nan\n",
      "31/46 [===================>..........] - ETA: 0s - loss: nan - root_mean_squared_error: nan\n",
      "42/46 [==========================>...] - ETA: 0s - loss: nan - root_mean_squared_error: nan\n",
      "46/46 [==============================] - 0s 6ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "\n",
      "Epoch 3/3                                                                      \n",
      "\n",
      " 1/46 [..............................] - ETA: 0s - loss: nan - root_mean_squared_error: nan\n",
      "11/46 [======>.......................] - ETA: 0s - loss: nan - root_mean_squared_error: nan\n",
      "20/46 [============>.................] - ETA: 0s - loss: nan - root_mean_squared_error: nan\n",
      "26/46 [===============>..............] - ETA: 0s - loss: nan - root_mean_squared_error: nan\n",
      "35/46 [=====================>........] - ETA: 0s - loss: nan - root_mean_squared_error: nan\n",
      "44/46 [===========================>..] - ETA: 0s - loss: nan - root_mean_squared_error: nan\n",
      "46/46 [==============================] - 0s 8ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "\n",
      " 1/39 [..............................] - ETA: 1s - loss: nan - root_mean_squared_error: nan\n",
      "12/39 [========>.....................] - ETA: 0s - loss: nan - root_mean_squared_error: nan\n",
      "23/39 [================>.............] - ETA: 0s - loss: nan - root_mean_squared_error: nan\n",
      "35/39 [=========================>....] - ETA: 0s - loss: nan - root_mean_squared_error: nan\n",
      "39/39 [==============================] - 0s 5ms/step - loss: nan - root_mean_squared_error: nan\n",
      "\n",
      " 25%|██▌       | 2/8 [00:12<00:31,  5.25s/trial, best loss: 0.9118534326553345]INFO:tensorflow:Assets written to: /var/folders/ld/8bgljzsn4sx_x1lb3wl_mnnm0000gn/T/tmpr404ing6/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/ld/8bgljzsn4sx_x1lb3wl_mnnm0000gn/T/tmpr404ing6/model/data/model/assets\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3/8 [00:15<00:25,  5.07s/trial, best loss: 0.9118534326553345]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3                                                                      \n",
      "\n",
      " 1/46 [..............................] - ETA: 9s - loss: 54.7902 - root_mean_squared_error: 7.4020\n",
      " 9/46 [====>.........................] - ETA: 0s - loss: nan - root_mean_squared_error: nan       \n",
      "19/46 [===========>..................] - ETA: 0s - loss: nan - root_mean_squared_error: nan\n",
      "30/46 [==================>...........] - ETA: 0s - loss: nan - root_mean_squared_error: nan\n",
      "40/46 [=========================>....] - ETA: 0s - loss: nan - root_mean_squared_error: nan\n",
      "46/46 [==============================] - ETA: 0s - loss: nan - root_mean_squared_error: nan\n",
      "46/46 [==============================] - 1s 10ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "\n",
      "Epoch 2/3                                                                      \n",
      "\n",
      " 1/46 [..............................] - ETA: 0s - loss: nan - root_mean_squared_error: nan\n",
      " 6/46 [==>...........................] - ETA: 0s - loss: nan - root_mean_squared_error: nan\n",
      "16/46 [=========>....................] - ETA: 0s - loss: nan - root_mean_squared_error: nan\n",
      "26/46 [===============>..............] - ETA: 0s - loss: nan - root_mean_squared_error: nan\n",
      "36/46 [======================>.......] - ETA: 0s - loss: nan - root_mean_squared_error: nan\n",
      "46/46 [==============================] - ETA: 0s - loss: nan - root_mean_squared_error: nan\n",
      "46/46 [==============================] - 0s 7ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "\n",
      "Epoch 3/3                                                                      \n",
      "\n",
      " 1/46 [..............................] - ETA: 0s - loss: nan - root_mean_squared_error: nan\n",
      "11/46 [======>.......................] - ETA: 0s - loss: nan - root_mean_squared_error: nan\n",
      "21/46 [============>.................] - ETA: 0s - loss: nan - root_mean_squared_error: nan\n",
      "31/46 [===================>..........] - ETA: 0s - loss: nan - root_mean_squared_error: nan\n",
      "41/46 [=========================>....] - ETA: 0s - loss: nan - root_mean_squared_error: nan\n",
      "46/46 [==============================] - 0s 7ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "\n",
      " 1/39 [..............................] - ETA: 1s - loss: nan - root_mean_squared_error: nan\n",
      "11/39 [=======>......................] - ETA: 0s - loss: nan - root_mean_squared_error: nan\n",
      "22/39 [===============>..............] - ETA: 0s - loss: nan - root_mean_squared_error: nan\n",
      "33/39 [========================>.....] - ETA: 0s - loss: nan - root_mean_squared_error: nan\n",
      "39/39 [==============================] - 0s 5ms/step - loss: nan - root_mean_squared_error: nan\n",
      "\n",
      " 38%|███▊      | 3/8 [00:17<00:25,  5.07s/trial, best loss: 0.9118534326553345]INFO:tensorflow:Assets written to: /var/folders/ld/8bgljzsn4sx_x1lb3wl_mnnm0000gn/T/tmpuyz3yvnl/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/ld/8bgljzsn4sx_x1lb3wl_mnnm0000gn/T/tmpuyz3yvnl/model/data/model/assets\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 4/8 [00:20<00:20,  5.00s/trial, best loss: 0.9118534326553345]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3                                                                      \n",
      "\n",
      " 1/46 [..............................] - ETA: 10s - loss: 37.4712 - root_mean_squared_error: 6.1214\n",
      " 8/46 [====>.........................] - ETA: 0s - loss: 35.9004 - root_mean_squared_error: 5.9917 \n",
      "17/46 [==========>...................] - ETA: 0s - loss: 34.7615 - root_mean_squared_error: 5.8959\n",
      "26/46 [===============>..............] - ETA: 0s - loss: 34.0676 - root_mean_squared_error: 5.8367\n",
      "36/46 [======================>.......] - ETA: 0s - loss: 33.7260 - root_mean_squared_error: 5.8074\n",
      "46/46 [==============================] - ETA: 0s - loss: 33.1961 - root_mean_squared_error: 5.7616\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 33.1961 - root_mean_squared_error: 5.7616 - val_loss: 30.8400 - val_root_mean_squared_error: 5.5534\n",
      "\n",
      "Epoch 2/3                                                                      \n",
      "\n",
      " 1/46 [..............................] - ETA: 0s - loss: 30.1946 - root_mean_squared_error: 5.4950\n",
      "11/46 [======>.......................] - ETA: 0s - loss: 30.0016 - root_mean_squared_error: 5.4774\n",
      "21/46 [============>.................] - ETA: 0s - loss: 29.6089 - root_mean_squared_error: 5.4414\n",
      "31/46 [===================>..........] - ETA: 0s - loss: 29.1449 - root_mean_squared_error: 5.3986\n",
      "41/46 [=========================>....] - ETA: 0s - loss: 28.7528 - root_mean_squared_error: 5.3622\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 28.4869 - root_mean_squared_error: 5.3373 - val_loss: 26.5316 - val_root_mean_squared_error: 5.1509\n",
      "\n",
      "Epoch 3/3                                                                      \n",
      "\n",
      " 1/46 [..............................] - ETA: 0s - loss: 26.7727 - root_mean_squared_error: 5.1742\n",
      "11/46 [======>.......................] - ETA: 0s - loss: 25.7188 - root_mean_squared_error: 5.0714\n",
      "21/46 [============>.................] - ETA: 0s - loss: 25.3028 - root_mean_squared_error: 5.0302\n",
      "31/46 [===================>..........] - ETA: 0s - loss: 24.8996 - root_mean_squared_error: 4.9899\n",
      "41/46 [=========================>....] - ETA: 0s - loss: 24.5914 - root_mean_squared_error: 4.9590\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 24.4241 - root_mean_squared_error: 4.9421 - val_loss: 22.8249 - val_root_mean_squared_error: 4.7775\n",
      "\n",
      " 1/39 [..............................] - ETA: 1s - loss: 23.8758 - root_mean_squared_error: 4.8863\n",
      "13/39 [=========>....................] - ETA: 0s - loss: 22.7153 - root_mean_squared_error: 4.7661\n",
      "25/39 [==================>...........] - ETA: 0s - loss: 22.9430 - root_mean_squared_error: 4.7899\n",
      "38/39 [============================>.] - ETA: 0s - loss: 22.9487 - root_mean_squared_error: 4.7905\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 22.9599 - root_mean_squared_error: 4.7916\n",
      "\n",
      " 50%|█████     | 4/8 [00:22<00:20,  5.00s/trial, best loss: 0.9118534326553345]INFO:tensorflow:Assets written to: /var/folders/ld/8bgljzsn4sx_x1lb3wl_mnnm0000gn/T/tmpq4wt9t_6/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/ld/8bgljzsn4sx_x1lb3wl_mnnm0000gn/T/tmpq4wt9t_6/model/data/model/assets\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 5/8 [00:25<00:14,  4.97s/trial, best loss: 0.9118534326553345]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3                                                                      \n",
      "\n",
      " 1/46 [..............................] - ETA: 8s - loss: 32.7152 - root_mean_squared_error: 5.7197\n",
      " 9/46 [====>.........................] - ETA: 0s - loss: 13.4671 - root_mean_squared_error: 3.6698\n",
      "19/46 [===========>..................] - ETA: 0s - loss: 8.1681 - root_mean_squared_error: 2.8580 \n",
      "29/46 [=================>............] - ETA: 0s - loss: 6.4788 - root_mean_squared_error: 2.5453\n",
      "39/46 [========================>.....] - ETA: 0s - loss: 5.5630 - root_mean_squared_error: 2.3586\n",
      "46/46 [==============================] - ETA: 0s - loss: 5.1249 - root_mean_squared_error: 2.2638\n",
      "46/46 [==============================] - 1s 10ms/step - loss: 5.1249 - root_mean_squared_error: 2.2638 - val_loss: 2.9268 - val_root_mean_squared_error: 1.7108\n",
      "\n",
      "Epoch 2/3                                                                      \n",
      "\n",
      " 1/46 [..............................] - ETA: 0s - loss: 2.4159 - root_mean_squared_error: 1.5543\n",
      "11/46 [======>.......................] - ETA: 0s - loss: 2.6349 - root_mean_squared_error: 1.6232\n",
      "21/46 [============>.................] - ETA: 0s - loss: 2.6320 - root_mean_squared_error: 1.6223\n",
      "31/46 [===================>..........] - ETA: 0s - loss: 2.5666 - root_mean_squared_error: 1.6020\n",
      "41/46 [=========================>....] - ETA: 0s - loss: 2.4899 - root_mean_squared_error: 1.5779\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 2.4706 - root_mean_squared_error: 1.5718 - val_loss: 2.2739 - val_root_mean_squared_error: 1.5080\n",
      "\n",
      "Epoch 3/3                                                                      \n",
      "\n",
      " 1/46 [..............................] - ETA: 0s - loss: 2.1780 - root_mean_squared_error: 1.4758\n",
      "10/46 [=====>........................] - ETA: 0s - loss: 2.0745 - root_mean_squared_error: 1.4403\n",
      "19/46 [===========>..................] - ETA: 0s - loss: 2.1048 - root_mean_squared_error: 1.4508\n",
      "28/46 [=================>............] - ETA: 0s - loss: 2.0402 - root_mean_squared_error: 1.4284\n",
      "37/46 [=======================>......] - ETA: 0s - loss: 1.9966 - root_mean_squared_error: 1.4130\n",
      "46/46 [==============================] - ETA: 0s - loss: 1.9411 - root_mean_squared_error: 1.3933\n",
      "46/46 [==============================] - 0s 8ms/step - loss: 1.9411 - root_mean_squared_error: 1.3933 - val_loss: 1.7853 - val_root_mean_squared_error: 1.3361\n",
      "\n",
      " 1/39 [..............................] - ETA: 1s - loss: 2.2842 - root_mean_squared_error: 1.5114\n",
      "11/39 [=======>......................] - ETA: 0s - loss: 1.8343 - root_mean_squared_error: 1.3544\n",
      "22/39 [===============>..............] - ETA: 0s - loss: 1.9897 - root_mean_squared_error: 1.4106\n",
      "33/39 [========================>.....] - ETA: 0s - loss: 1.9102 - root_mean_squared_error: 1.3821\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 1.8835 - root_mean_squared_error: 1.3724\n",
      "\n",
      " 62%|██████▎   | 5/8 [00:26<00:14,  4.97s/trial, best loss: 0.9118534326553345]INFO:tensorflow:Assets written to: /var/folders/ld/8bgljzsn4sx_x1lb3wl_mnnm0000gn/T/tmp90koi6d4/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/ld/8bgljzsn4sx_x1lb3wl_mnnm0000gn/T/tmp90koi6d4/model/data/model/assets\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 6/8 [00:30<00:09,  4.97s/trial, best loss: 0.9118534326553345]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3                                                                      \n",
      "\n",
      " 1/46 [..............................] - ETA: 8s - loss: 26.7731 - root_mean_squared_error: 5.1743\n",
      " 9/46 [====>.........................] - ETA: 0s - loss: 25.5869 - root_mean_squared_error: 5.0583\n",
      "19/46 [===========>..................] - ETA: 0s - loss: 23.8163 - root_mean_squared_error: 4.8802\n",
      "29/46 [=================>............] - ETA: 0s - loss: 22.5924 - root_mean_squared_error: 4.7531\n",
      "38/46 [=======================>......] - ETA: 0s - loss: 21.6719 - root_mean_squared_error: 4.6553\n",
      "46/46 [==============================] - ETA: 0s - loss: 20.9815 - root_mean_squared_error: 4.5806\n",
      "46/46 [==============================] - 1s 10ms/step - loss: 20.9815 - root_mean_squared_error: 4.5806 - val_loss: 16.6492 - val_root_mean_squared_error: 4.0803\n",
      "\n",
      "Epoch 2/3                                                                      \n",
      "\n",
      " 1/46 [..............................] - ETA: 0s - loss: 16.3752 - root_mean_squared_error: 4.0466\n",
      "11/46 [======>.......................] - ETA: 0s - loss: 15.5806 - root_mean_squared_error: 3.9472\n",
      "21/46 [============>.................] - ETA: 0s - loss: 14.7341 - root_mean_squared_error: 3.8385\n",
      "31/46 [===================>..........] - ETA: 0s - loss: 14.0163 - root_mean_squared_error: 3.7438\n",
      "41/46 [=========================>....] - ETA: 0s - loss: 13.3577 - root_mean_squared_error: 3.6548\n",
      "46/46 [==============================] - 0s 7ms/step - loss: 13.1365 - root_mean_squared_error: 3.6244 - val_loss: 10.9141 - val_root_mean_squared_error: 3.3037\n",
      "\n",
      "Epoch 3/3                                                                      \n",
      "\n",
      " 1/46 [..............................] - ETA: 0s - loss: 12.0070 - root_mean_squared_error: 3.4651\n",
      "11/46 [======>.......................] - ETA: 0s - loss: 10.5044 - root_mean_squared_error: 3.2410\n",
      "21/46 [============>.................] - ETA: 0s - loss: 9.9066 - root_mean_squared_error: 3.1475 \n",
      "31/46 [===================>..........] - ETA: 0s - loss: 9.4650 - root_mean_squared_error: 3.0765\n",
      "41/46 [=========================>....] - ETA: 0s - loss: 8.9767 - root_mean_squared_error: 2.9961\n",
      "46/46 [==============================] - 0s 6ms/step - loss: 8.7817 - root_mean_squared_error: 2.9634 - val_loss: 7.7546 - val_root_mean_squared_error: 2.7847\n",
      "\n",
      " 1/39 [..............................] - ETA: 1s - loss: 7.8999 - root_mean_squared_error: 2.8107\n",
      "13/39 [=========>....................] - ETA: 0s - loss: 7.5773 - root_mean_squared_error: 2.7527\n",
      "26/39 [===================>..........] - ETA: 0s - loss: 7.8359 - root_mean_squared_error: 2.7993\n",
      "39/39 [==============================] - ETA: 0s - loss: 7.7758 - root_mean_squared_error: 2.7885\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 7.7758 - root_mean_squared_error: 2.7885\n",
      "\n",
      " 75%|███████▌  | 6/8 [00:31<00:09,  4.97s/trial, best loss: 0.9118534326553345]INFO:tensorflow:Assets written to: /var/folders/ld/8bgljzsn4sx_x1lb3wl_mnnm0000gn/T/tmphd_watah/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/ld/8bgljzsn4sx_x1lb3wl_mnnm0000gn/T/tmphd_watah/model/data/model/assets\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 7/8 [00:35<00:04,  4.94s/trial, best loss: 0.9118534326553345]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3                                                                      \n",
      "\n",
      " 1/46 [..............................] - ETA: 8s - loss: 17.1231 - root_mean_squared_error: 4.1380\n",
      " 9/46 [====>.........................] - ETA: 0s - loss: nan - root_mean_squared_error: nan       \n",
      "19/46 [===========>..................] - ETA: 0s - loss: nan - root_mean_squared_error: nan\n",
      "29/46 [=================>............] - ETA: 0s - loss: nan - root_mean_squared_error: nan\n",
      "39/46 [========================>.....] - ETA: 0s - loss: nan - root_mean_squared_error: nan\n",
      "45/46 [============================>.] - ETA: 0s - loss: nan - root_mean_squared_error: nan\n",
      "46/46 [==============================] - 1s 11ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "\n",
      "Epoch 2/3                                                                      \n",
      "\n",
      " 1/46 [..............................] - ETA: 0s - loss: nan - root_mean_squared_error: nan\n",
      "11/46 [======>.......................] - ETA: 0s - loss: nan - root_mean_squared_error: nan\n",
      "21/46 [============>.................] - ETA: 0s - loss: nan - root_mean_squared_error: nan\n",
      "31/46 [===================>..........] - ETA: 0s - loss: nan - root_mean_squared_error: nan\n",
      "41/46 [=========================>....] - ETA: 0s - loss: nan - root_mean_squared_error: nan\n",
      "46/46 [==============================] - 0s 6ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "\n",
      "Epoch 3/3                                                                      \n",
      "\n",
      " 1/46 [..............................] - ETA: 0s - loss: nan - root_mean_squared_error: nan\n",
      "10/46 [=====>........................] - ETA: 0s - loss: nan - root_mean_squared_error: nan\n",
      "20/46 [============>.................] - ETA: 0s - loss: nan - root_mean_squared_error: nan\n",
      "30/46 [==================>...........] - ETA: 0s - loss: nan - root_mean_squared_error: nan\n",
      "40/46 [=========================>....] - ETA: 0s - loss: nan - root_mean_squared_error: nan\n",
      "46/46 [==============================] - 0s 7ms/step - loss: nan - root_mean_squared_error: nan - val_loss: nan - val_root_mean_squared_error: nan\n",
      "\n",
      " 1/39 [..............................] - ETA: 1s - loss: nan - root_mean_squared_error: nan\n",
      "12/39 [========>.....................] - ETA: 0s - loss: nan - root_mean_squared_error: nan\n",
      "24/39 [=================>............] - ETA: 0s - loss: nan - root_mean_squared_error: nan\n",
      "36/39 [==========================>...] - ETA: 0s - loss: nan - root_mean_squared_error: nan\n",
      "39/39 [==============================] - 0s 5ms/step - loss: nan - root_mean_squared_error: nan\n",
      "\n",
      " 88%|████████▊ | 7/8 [00:36<00:04,  4.94s/trial, best loss: 0.9118534326553345]INFO:tensorflow:Assets written to: /var/folders/ld/8bgljzsn4sx_x1lb3wl_mnnm0000gn/T/tmp3n6z1kvn/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/ld/8bgljzsn4sx_x1lb3wl_mnnm0000gn/T/tmp3n6z1kvn/model/data/model/assets\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:40<00:00,  5.01s/trial, best loss: 0.9118534326553345]\n",
      "INFO:tensorflow:Assets written to: /var/folders/ld/8bgljzsn4sx_x1lb3wl_mnnm0000gn/T/tmpkztpu109/model/data/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/ld/8bgljzsn4sx_x1lb3wl_mnnm0000gn/T/tmpkztpu109/model/data/model/assets\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'lr': 0.0031683216722915046, 'momentum': 0.712097687201572}\n",
      "Best eval rmse: 0.9118534326553345\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"/wine-quality\")\n",
    "with mlflow.start_run():\n",
    "    # Conduct the hyperparameter search using Hyperopt\n",
    "    trials = Trials()\n",
    "    best = fmin(\n",
    "        fn=objective,\n",
    "        space=space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=8,\n",
    "        trials=trials,\n",
    "    )\n",
    "\n",
    "    # Fetch the details of the best run\n",
    "    best_run = sorted(trials.results, key=lambda x: x[\"eval_rmse\"])[0]\n",
    "\n",
    "    # Log the best parameters, loss, and model\n",
    "    mlflow.log_params(best)\n",
    "    mlflow.log_metric(\"eval_rmse\", best_run[\"loss\"])\n",
    "    mlflow.tensorflow.log_model(best_run[\"model\"], \"model\", signature=signature)\n",
    "\n",
    "    # Print out the best parameters and corresponding loss\n",
    "    print(f\"Best parameters: {best}\")\n",
    "    print(f\"Best eval rmse: {best_run['eval_rmse']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
